{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complex-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import cl\n",
    "import utils as ut\n",
    "import numpy as np\n",
    "from skimage.morphology import binary_dilation\n",
    "import proc3d\n",
    "import json\n",
    "from PIL import Image\n",
    "from utils import *\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "related-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "class space_carving_2():\n",
    "    def __init__(self, dataset_path):\n",
    "        self.masks_files = sorted (glob.glob(os.path.join(dataset_path, 'masks', '*.png')) )#get all .png file names from folder path\n",
    "        self.extrinsics = self.load_extrinsics(os.path.join(dataset_path, 'extrinsics'))\n",
    "        self.bbox = json.load(open(os.path.join(dataset_path, 'bbox.json')))\n",
    "        self.camera_model = json.load(open(os.path.join(dataset_path, 'camera_model.json')))\n",
    "        self.intrinsics= self.camera_model['params'][0:4]\n",
    "        \n",
    "        params = json.load(open(os.path.join(dataset_path, 'params.json')))\n",
    "        self.gt=o3d.io.read_point_cloud(params[\"gt_path\"])\n",
    "        self.gt_points = np.asarray(self.gt.points)\n",
    "        self.n_dilation=params[\"sc\"][\"n_dilation\"]\n",
    "        self.voxel_size = params['sc']['voxel_size']\n",
    "        \n",
    "        self.set_sc(self.bbox)\n",
    "        \n",
    "    def reset(self):\n",
    "        del(self.sc)\n",
    "        self.set_sc(self.bbox) \n",
    "        \n",
    "    def load_extrinsics(self,path):\n",
    "        ext = []\n",
    "        ext_files = glob.glob(os.path.join(path, '*.json'))\n",
    "        assert len(ext_files) != 0,\"json list is empty.\"\n",
    "        for i in sorted(ext_files):                                                                                                                                     \n",
    "            ext.append(json.load(open(i)))                                                                                                                                                                                                                                                  \n",
    "        return ext \n",
    "    \n",
    "    def load_mask(self,idx):                                                                                                                                         \n",
    "        img = cv2.imread(self.masks_files[idx], cv2.IMREAD_GRAYSCALE)                                                                                                                                                                                                                                                                                                                                                                                     \n",
    "        return img\n",
    "\n",
    "    def set_sc(self,bbox):\n",
    "        x_min, x_max = bbox['x']\n",
    "        y_min, y_max = bbox['y']\n",
    "        z_min, z_max = bbox['z']\n",
    "\n",
    "        nx = int((x_max - x_min) / self.voxel_size) + 1\n",
    "        ny = int((y_max - y_min) / self.voxel_size) + 1\n",
    "        nz = int((z_max - z_min) / self.voxel_size) + 1\n",
    "\n",
    "        self.origin = np.array([x_min, y_min, z_min])\n",
    "        self.sc = cl.Backprojection([nx, ny, nz], [x_min, y_min, z_min], self.voxel_size)\n",
    "\n",
    "    def carve(self,idx):\n",
    "        im = self.load_mask(idx)\n",
    "        self.space_carve(im, self.extrinsics[idx])\n",
    "        \n",
    "    def space_carve(self, mask, rt):\n",
    "        #mask = im.copy() #get_mask(im)\n",
    "        rot = sum(rt['R'], [])\n",
    "        tvec = rt['T']\n",
    "        if self.n_dilation:\n",
    "            for k in range(self.n_dilation): mask = binary_dilation(mask)    \n",
    "        self.sc.process_view(self.intrinsics, rot, tvec, mask)\n",
    "        \n",
    "    def dist_to_gt(self):\n",
    "        vol = self.sc.values().copy()\n",
    "        vol = vol.reshape(self.sc.shape)\n",
    "        pcd=proc3d.vol2pcd_exp(vol, self.origin, self.voxel_size, level_set_value=0) \n",
    "        pcd_p = np.asarray(pcd.points)\n",
    "        cd=chamfer_d(self.gt_points , pcd_p)\n",
    "        return cd\n",
    "\n",
    "    \n",
    "def create_pdict(name):\n",
    "    pdict = {'name':name,'hlines':[],'cumulative_hlines':[],}\n",
    "    return pdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nearby-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/pico/uni/romi/rl_sony/arabidopsis_image_sets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "frozen-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "plants = [create_pdict('000_2d'), create_pdict('001_2d'),\n",
    "          create_pdict('003_2d'), create_pdict('006_2d'),\n",
    "          create_pdict('009_2d'), create_pdict('124_2d'),\n",
    "          create_pdict('195_2d')]\n",
    "\n",
    "for plant in plants:\n",
    "    sc = space_carving_2(os.path.join(data_path,plant['name']))\n",
    "    #carve all rows cumulatively\n",
    "    sc.reset()\n",
    "    for i in range(720):      \n",
    "        sc.carve(i)\n",
    "        if (i+1)%180 == 0: #take cumulative chamfer distance from ground truth for each row\n",
    "            ch_dist = sc.dist_to_gt()\n",
    "            plant['cumulative_hlines'].append(ch_dist)\n",
    "            #print(i,ch_dist)\n",
    "    #first row of cumulative distance is the same as first row of independent distances\n",
    "    plant['hlines'].append(plant['cumulative_hlines'][0])\n",
    "    #carve rows independently\n",
    "    for i in range(180,720,180):\n",
    "        sc.reset()\n",
    "        for j in range(180):\n",
    "            sc.carve(i+j)\n",
    "        ch_dist = sc.dist_to_gt()\n",
    "        plant['hlines'].append(ch_dist)\n",
    "        #print(i+j,ch_dist)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "rotary-emergency",
   "metadata": {},
   "source": [
    "#save collected data to json\n",
    "plants_dict = {}\n",
    "for plant in plants:\n",
    "    plants_dict[plant['name']] = plant\n",
    "    \n",
    "with open('cum_distances_plants.json', 'w') as json_file:\n",
    "            json.dump(plants_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "under-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "plants = json.load(open('cum_distances_plants.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rotary-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_carve(msc,imgs):\n",
    "    msc.reset()\n",
    "    for i in imgs:\n",
    "        msc.carve(i)\n",
    "        #print(np.unique(spc.sc.values()))\n",
    "    cd = msc.dist_to_gt()\n",
    "    return cd\n",
    "\n",
    "def rnd_test(sc,n,set_size,sample_type='1d'):\n",
    "    distances = []\n",
    "    for i in range(n):\n",
    "        if sample_type == '1d':\n",
    "            images = np.random.randint(180, size=set_size)\n",
    "        else:\n",
    "            images = np.random.randint(720, size=set_size)\n",
    "        distances.append( test_carve(sc,images) )\n",
    "        print(f\"{i}       \",end='\\r')\n",
    "    return np.mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "distributed-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = space_carving_2(os.path.join(data_path,'003_2d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "latest-blade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5011068110092415"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_test(sc,100,20,'1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "accessible-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000_2d 10\n",
      "000_2d 20\n",
      "000_2d 30\n",
      "000_2d 40\n",
      "000_2d 50\n",
      "000_2d 60\n",
      "000_2d 70\n",
      "000_2d 80\n",
      "000_2d 90\n",
      "000_2d 100\n",
      "000_2d 110\n",
      "000_2d 120\n",
      "000_2d 130\n",
      "000_2d 140\n",
      "000_2d 150\n",
      "001_2d 10\n",
      "001_2d 20\n",
      "001_2d 30\n",
      "001_2d 40\n",
      "001_2d 50\n",
      "001_2d 60\n",
      "001_2d 70\n",
      "001_2d 80\n",
      "001_2d 90\n",
      "001_2d 100\n",
      "001_2d 110\n",
      "001_2d 120\n",
      "001_2d 130\n",
      "001_2d 140\n",
      "001_2d 150\n",
      "003_2d 10\n",
      "003_2d 20\n",
      "003_2d 30\n",
      "003_2d 40\n",
      "003_2d 50\n",
      "003_2d 60\n",
      "003_2d 70\n",
      "003_2d 80\n",
      "003_2d 90\n",
      "003_2d 100\n",
      "003_2d 110\n",
      "003_2d 120\n",
      "003_2d 130\n",
      "003_2d 140\n",
      "003_2d 150\n",
      "006_2d 10\n",
      "006_2d 20\n",
      "006_2d 30\n",
      "006_2d 40\n",
      "006_2d 50\n",
      "006_2d 60\n",
      "006_2d 70\n",
      "006_2d 80\n",
      "006_2d 90\n",
      "006_2d 100\n",
      "006_2d 110\n",
      "006_2d 120\n",
      "006_2d 130\n",
      "006_2d 140\n",
      "006_2d 150\n",
      "009_2d 10\n",
      "009_2d 20\n",
      "009_2d 30\n",
      "009_2d 40\n",
      "009_2d 50\n",
      "009_2d 60\n",
      "009_2d 70\n",
      "009_2d 80\n",
      "009_2d 90\n",
      "009_2d 100\n",
      "009_2d 110\n",
      "009_2d 120\n",
      "009_2d 130\n",
      "009_2d 140\n",
      "009_2d 150\n",
      "124_2d 10\n",
      "124_2d 20\n",
      "124_2d 30\n",
      "124_2d 40\n",
      "124_2d 50\n",
      "124_2d 60\n",
      "124_2d 70\n",
      "124_2d 80\n",
      "124_2d 90\n",
      "124_2d 100\n",
      "124_2d 110\n",
      "124_2d 120\n",
      "124_2d 130\n",
      "124_2d 140\n",
      "124_2d 150\n",
      "195_2d 10\n",
      "195_2d 20\n",
      "195_2d 30\n",
      "195_2d 40\n",
      "195_2d 50\n",
      "195_2d 60\n",
      "195_2d 70\n",
      "195_2d 80\n",
      "195_2d 90\n",
      "195_2d 100\n",
      "195_2d 110\n",
      "195_2d 120\n",
      "195_2d 130\n",
      "195_2d 140\n",
      "195_2d 150\n",
      "99       \r"
     ]
    }
   ],
   "source": [
    "for plant in plants.values():\n",
    "    sc = space_carving_2(os.path.join(data_path,plant['name']))\n",
    "    plant['rnd_1d'] = []\n",
    "    plant['rnd_2d'] = []\n",
    "    for i in range(10,151,10):\n",
    "        print(plant['name'],i)\n",
    "        plant['rnd_1d'].append(rnd_test(sc,100,i,'1d'))\n",
    "        plant['rnd_2d'].append(rnd_test(sc,100,i,'2d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "photographic-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cum_distances_plants.json', 'w') as json_file:\n",
    "            json.dump(plants, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-burton",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
